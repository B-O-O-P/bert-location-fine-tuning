{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from nltk import WordNetLemmatizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, TensorDataset, random_split\n",
    "\n",
    "from string import punctuation\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel, BertForPreTraining, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Dima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text            loc\n0  Light shone through the wintry branches, shado...  ancient ruins\n1  The columns were the only complete thing, ever...  ancient ruins\n2  Pre-Columbian civilisations firmly left their ...  ancient ruins\n3  Uxmal and its giant Pyramid of the Magician ap...  ancient ruins\n4  When picturing ancient ruins, the Middle East ...  ancient ruins",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>loc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Light shone through the wintry branches, shado...</td>\n      <td>ancient ruins</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The columns were the only complete thing, ever...</td>\n      <td>ancient ruins</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pre-Columbian civilisations firmly left their ...</td>\n      <td>ancient ruins</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Uxmal and its giant Pyramid of the Magician ap...</td>\n      <td>ancient ruins</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>When picturing ancient ruins, the Middle East ...</td>\n      <td>ancient ruins</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 3
    }
   ],
   "source": [
    "data = pd.read_csv('data/dataset_base.csv')\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "261\n",
      "261\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "un_texts = list(data['text'])\n",
    "\n",
    "un_labels = list(data['loc'])\n",
    "\n",
    "print(len(un_texts))\n",
    "print(len(un_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "the hills that lie friendly in the day  like the pillows of the land  are darkly ominous by night the paths that were illuminated just hours before become lost in a blackness that even moonlight cannot help the trees that are magnificent in sunshine tower over james as he steps across the borderline between the seen and unseen\n",
      "['hill']\n",
      "583\n",
      "583\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "texts = []\n",
    "labels = []\n",
    "\n",
    "for text, label_str in list(zip(un_texts, un_labels)):\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    label = label_str.split()\n",
    "    for sentence in sentences:\n",
    "        lowered_text = (text.translate(str.maketrans('', '', punctuation))).lower()\n",
    "        if all(word in lowered_text for word in label):\n",
    "            texts.append(lowered_text)\n",
    "            labels.append(label)\n",
    "\n",
    "print(texts[300])\n",
    "print(labels[300])\n",
    "print(len(texts))\n",
    "print(len(labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "max_words = 256"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def one_hot_background(words, label_array):\n",
    "    words_no = words.split(' ')\n",
    "\n",
    "    Lem = WordNetLemmatizer()\n",
    "    words = [Lem.lemmatize(word) for word in words_no]\n",
    "    N = max_words\n",
    "    one_hot_label = np.zeros(N)\n",
    "    \n",
    "    for i in range(len(words)):\n",
    "        if words[i] in label_array:\n",
    "            one_hot_label[i] = 1\n",
    "    \n",
    "    return np.array(one_hot_label, dtype=np.float64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "d:\\github\\b-o-o-p\\diplom\\bert-location-fine-tuning\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Original:  light shone through the wintry branches shadowy arms stretching across the ancient ruins what was left stood in spite of itself defying gravity in its precarious way yet this place kept secret by the trees was safe it had avoided modern mans destructive touch and so had become a sanctuary for the animals\n",
      "Token IDs: tensor([  101,  2422, 14707,  2083,  1996,  2663, 11129,  5628, 22801,  2608,\n",
      "        10917,  2408,  1996,  3418,  8435,  2054,  2001,  2187,  2768,  1999,\n",
      "         8741,  1997,  2993, 13366, 14147,  8992,  1999,  2049,  3653, 10010,\n",
      "         6313,  2126,  2664,  2023,  2173,  2921,  3595,  2011,  1996,  3628,\n",
      "         2001,  3647,  2009,  2018,  9511,  2715, 16042, 15615,  3543,  1998,\n",
      "         2061,  2018,  2468,  1037,  8493,  2005,  1996,  4176,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "for text in texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 256,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "print('Original: ', texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "torch.Size([583, 256])\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(input_ids.size())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[CLS] light shone through the wintry branches shadowy arms stretching across the ancient ruins what was left stood in spite of itself defying gravity in its precarious way yet this place kept secret by the trees was safe it had avoided modern mans destructive touch and so had become a sanctuary for the animals [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "decoded_texts = list(map(lambda id: tokenizer.decode(id), input_ids))\n",
    "\n",
    "for i  in range(len(labels)):\n",
    "    label = labels[i]\n",
    "    labels[i] = one_hot_background(decoded_texts[i], label)\n",
    "\n",
    "labels = np.array(labels)\n",
    "print(decoded_texts[0])\n",
    "print(labels[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "583\n",
      "583\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "N = len(texts)\n",
    "\n",
    "train_size = int(N * 0.8)\n",
    "val_size = int(N * 0.1)\n",
    "test_size = (N - train_size - val_size)\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, torch.tensor(labels))\n",
    "print(len(dataset))\n",
    "print(sum([train_size, val_size, test_size]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset, sampler=RandomSampler(dataset), batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "cuda selected\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import torch\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"cuda selected\")\n",
    "# If not...\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"cpu selected\")\n",
    "    \n",
    "device = torch.device( \"cpu\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states = True, )\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, input_ids, input_mask=None, token_type_ids=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=token_type_ids)\n",
    "        output = output[0]\n",
    "        # print(\" BERT output: {}\".format(output))\n",
    "        y_pred = self.linear(output)\n",
    "        return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model = BERT()\n",
    "clear_output(wait=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.load_state_dict(torch.load('models/bert-location-transformer-epoch-5.pt'))\n",
    "model.to(device)\n",
    "clear_output(wait=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def accuracy(pred, label, verbose=False):\n",
    "    pred_words = []\n",
    "    label_words = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == 1:\n",
    "            pred_words.append(i)\n",
    "    for i in range(len(label)):\n",
    "        if label[i] == 1:\n",
    "            label_words.append(i)\n",
    "    if verbose:\n",
    "        print(pred_words)\n",
    "        print(label_words)\n",
    "    return all(word in pred_words for word in label_words)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "===== Testing =====\n",
      "tensor([[-13.0026, -13.8098,  11.4634,  ..., -14.7691, -14.7786, -14.8253],\n",
      "        [ -9.2334,  -8.4910,  10.5309,  ...,  -6.7507, -11.7169, -12.4587],\n",
      "        [-11.0499,  -8.7605,   6.1448,  ..., -13.9319, -14.1909, -14.2747],\n",
      "        ...,\n",
      "        [-12.8546,   0.3021, -13.5244,  ..., -14.8782, -14.8911, -14.8895],\n",
      "        [-12.6446, -13.5865,  -5.6381,  ..., -14.9370, -14.9371, -14.9426],\n",
      "        [-14.2321, -14.4980, -14.0887,  ..., -15.0386, -15.0378, -15.0399]])\n",
      "torch.Size([8, 256])\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1487454fe601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy: {0:.2f}%\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_accuracy\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnb_eval_steps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ],
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "log_steps = 5\n",
    "\n",
    "\n",
    "print(5*\"=\", \"Testing\", 5*\"=\")\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    b_input_ids = batch[0]\n",
    "    b_input_mask = batch[1]\n",
    "    b_labels = batch[2].long()\n",
    "        \n",
    "    with torch.no_grad():        \n",
    "        logits = model(b_input_ids, b_input_mask).squeeze()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        logits = np.array([np.array(list(map(lambda x: 1 if x > 0 else 0, l))) for l in logits])\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        tmp_eval_accuracy = 0\n",
    "        for (logit, label) in zip(logits, label_ids):\n",
    "            tmp_eval_accuracy += accuracy(logit, label)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += batch_size\n",
    "        \n",
    "    if step % log_steps == 0 and step:\n",
    "        print('  STEP {} accuracy: {}'.format(step, eval_accuracy  / nb_eval_steps * 100))\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Test accuracy: {0:.2f}%\".format(eval_accuracy / nb_eval_steps * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = 'London is the capital and largest city of England and the United Kingdom, and is the largest urban area in Greater London.'\n",
    "\n",
    "text = text.translate(str.maketrans('', '', punctuation)).lower()\n",
    "\n",
    "encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 256,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "input_id = encoded_dict['input_ids'][0]\n",
    "attention_mask = encoded_dict['attention_mask'][0]\n",
    "\n",
    "print(input_id)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label = ['city', 'capital', 'area']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(input_id)\n",
    "\n",
    "label = one_hot_background(decoded_text, label)\n",
    "\n",
    "print(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_id = torch.tensor(np.atleast_2d(input_id))\n",
    "attention_mask = torch.tensor(np.atleast_2d(attention_mask))\n",
    "\n",
    "with torch.no_grad():        \n",
    "    logits = model(input_id, attention_mask).squeeze()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    logits = np.array(list(map(lambda x: 1 if x > 0 else 0, logits)))\n",
    "    label_ids = label\n",
    "    print(accuracy(logits, label, verbose=True))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}